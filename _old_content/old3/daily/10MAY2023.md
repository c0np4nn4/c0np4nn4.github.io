+++
title = "10MAY2023"
description = "ML"
date = 2023-05-10
toc = true

[taxonomies]
categories = ["Quick Review", "note"]
tags = ["Machine Learning"]

[extra]
math=true
+++

---

# ML
<mark>p. 23</mark>
- `hyper parameter` 는 정답이 없음
  - cross validation 을 하면서, hyperparameter 가 얼마나 적절한지 체크 하면 됨

$m=p$: Bagging

<mark>p. 25</mark>
- `Train`, `Validation`, `Test` 용도로 데이터를 구분(split)했을 때는 교집합이 없어야 함
> - `Training Set`을 이용해 모델을 학습
> - `Validation Set` 을 이용해 모델을 평가
>   - `hyper parameter`를 튜닝
>   - `Validation Set`으로 평가했을 때 가장 잘 훈련된 모델을 선택
> - `Test Set` 으로 결과를 확인

<mark>p. 26</mark>
`Variance` 와 `Bias` 를 기준으로, 데이터가 어떻게 분포되어 있는지를 살펴봄

<mark>p. 27</mark>
전체적인 그림 참고

<mark>p. 28~29</mark>
- ***K-Fold Cross Validation***
- 여러개의 `Validation Set` 을 이용해서 최적의 `Hyperparameter` 와 `Model` 을 결정함
- `hyper parameter` 를 결정한 뒤에는 `Train set`을 따로 둘 필요 없이 모든 데이터를 이용해서 평가하면 좋다고 함

<mark>29</mark> 에서는 ***10-Fold***
- 데이터의 수가 적을수록 큰 $K$ 가 유리함
  - <u>훈련에 쓰는 데이터의 비율이 커지기 때문에</u> 클수록 좋음
- 데이터의 수가 많으면 큰 $k$일 때, iteration 이 많이 일어나서 오버헤드가 커지기 때문에 작은 $k$ 도 충분함
- **stratified**: 클래스의 비율이 일정하게 유지
  - 유리한 이유?: `Training,  Test Set`이 전체 데이터의 분포를 표현할 수 있어야 하기 때문

---

## Deep Learning
- `Multi-Layer Perception` 을 시작으로 딥러닝 강의를 시작함..
### Perceptron
- `신경망`과 유사한 구조로 <txtred>인공신경망</txtred> 을 만듦
- 수상돌기에 도착한여러 신호가 세포체에 <txtred>합쳐짐</txtred>
  - $\mathbb{X} = \[x_1, x_2, \dots, x_n\]\in \mathbb{R}^n$ 가 합쳐진다.
  - 이 때, 각 요소들에 대한 가중치($w_k$) 를 곱해주면 `sensitivity` 를 정해줄 수 있음
  - 이를 벡터의 내적으로 표현하면 아래와 같음
  $$\mathbb{w}^T\mathbb{X}$$
  - 마치 뉴런과 같이 특정 값을 넘으면 신호가 전달되는 것을 수식으로 표현하면 아래와 같음
  $$\phi(x) = \begin{cases}
    1 \quad \text{where} \quad (\mathbb{w}^T\mathbb{x} > \tau) \newline
    -1 \quad \text{where} \quad (\mathbb{w}^T\mathbb{x} < \tau) \newline
  \end{cases}$$

- `Perceptron` 의 학습 규칙
  - $\mathbb{w}$ 값을 **0** 또는 **0**에 가까운 아주 작은 값으로 초기화
    - weight 를 초기화 하는 이유?
    - 모델에서 알고 있는 것: $\mathbb{x}$, $\phi(\mathbb{x})$
    - 따라서, $\mathbb{w}$ 를 찾아나감
  - 각 샘플 $\mathbb{x}$ 에 대한 출력값 $\hat{y}$ 와 $\hat{y} - y$ 값을 구함
  - $\mathbb{w}$ 업데이트 후 수렴할 떄까지 반복함

- *2차원 데이터에서 가중치를 업데이트*하는 예시
$$w_1x_1 + w_2x_2 = y$$
- `절편` 값에 대해 생각해보면, $\mathbb{w}$ 는 총 3개가 필요함
$$w_0 + w_1x_1 + w_2x_2 = y$$

$$\Delta w_0 = \eta(y - output)$$

$\eta$ 값: 

---

- 예측이 정확하면?
  - 모델의 업데이트가 일어나지 않음
  - (가중치가 그대로 유지)
- 예측이 틀리면?
  - 가중치가 업데이트 됨 ($\Delta w_j$ 값이 곧 업데이트 되는 크기)

---

# Computer Architecture
<mark>Principle of Locality</mark>
- 메모리 참조에 대한 *Locality*
  - Temporal
  - Spartial

<mark>Locality 활용</mark>
- `Memory Hierarchy`
  - *disk* 에 모든 정보를 저장해두고
  - *disk* 보다 <u>작고 빠른</u> DRAM 에 정보를 복사해옴

<mark>Memory Hierarchy Levels</mark>
- `Cache Hit` 와 `Cache Miss`

<mark>Memory Tech.</mark>
- `SRAM`, `DRAM`, `Magnetic disk`
- `Ideal Memory` 은 `SRAM` 의 속도에 `Magnetic Disk`의 공간을 갖는 메모리

<mark>DRAM Tech. </mark>
- 주기적으로 *refresh* 되어야 함
- 하나의 트랜지스터가 `capacity` 를 제어
