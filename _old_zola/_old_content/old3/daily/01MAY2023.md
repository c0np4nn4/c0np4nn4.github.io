+++
title = "01MAY2023"
description = "PL, Algorithm"
date = 2023-05-01
toc = true

[taxonomies]
categories = ["Quick Review"]
tags = ["PL", "Algorithm"]

[extra]
math=true
+++
---
# Machine Learning
- 차원 축소에 관한 강의를 들었음
- 선형대수학에 관한 지식이 많이 필요함 (eigenvalue 등등)
---
# Computer Architecutre
- Branch Hazard 나머지 내용과 
---
# ERP
## CNN
- `MLP` 와 달리, parameter 의 수가 적기 때문에 좋음
- 마지막에는 10개 중에 하나를 맞추는 등의 일을 해야함
  - `MLP` 에서와 같이 전부 연결된 Layer 를 구성해야함
- ***1-D, 2-D Discrete Convolution Definitions*** 수식.. 언급
---
p.34
- `padding`: padding 을 통해 경계값을 처리하는 방법
---
p.38
- `pooling`
  - MAX Pooling, 값을 3x3 에서 하나 뽑아내면 크기가 1/3 됨
---
p.39
- `Convolution w/ Multiple Channel`
`CNN` 에서는 RGB 인 3개짜리 채널로 최대한 많은 정보를 만들어내고 싶어함
- 3채널에서 5채널의 정보를 만들어냄
  - $m_1$ x $m_2$ 의 로컬 정보를 주목
  - $5$개의 필터가 있으면, $5$개의 데이터 셋을 만들어낼 수 있음
  - 4차원으로 필터를 나타낸 것
  - Pooling 을 통해서 크기를 줄임
---
p.40
- `validation set` 쓰는 이유: training set 에 overfitting 되는 것을 막음
- `Drop Out`
  - 훈련할 때, 몇몇 뉴런들에게 데이터를 안줌(훈련을 안시킴)
---
p.40
- `MLP` 얘기할 떄, 중간에 Non-Linear 함수도 껴줘야 함을 말함
- Sigmoid Function: (Logistic Regression)
- 렐루 함수: 공간을 반만 남기는 효과가 있음
---

## RNN
- 개요만 얘기함
- 앞에서는 정보가 떨어지면, 잘 processing 해서 정보를 만들어내는것
- `RNN` 의 `Recurrent`
---
- `Sequence Data`
  - 데이터가 연속적으로 들어옴
  - 데이터에 순서를 매길 수 있음
- ***앞뒤 관계(시간축 관계)***에 대한 구조적 고려도 필요하게 됨
---
