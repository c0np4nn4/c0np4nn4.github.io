+++
title = "ZKML, 논문 읽기"
date = "2024-05-13"
+++

> 
> 아직 작성 중 입니다.
> 

# 1. Introduction
머신러닝(ML) 알고리즘은 모델 크기, 접근성, 사용 범위가 급격히 증가하고 있습니다. 
특히 `코드 생성`, `교육`, 심지어 `법률` 및 `의료 시스템` 등 점점 더 민감한 분야에 더 크고 더 많은 기능을 갖춘 모델이 배포되고 있습니다.
이러한 여러 분야의 융합 추세로 인해, ML 모델에 **책임감**을 부여하는 것이 점점 더 필요해졌지만 이는 거의 불가능합니다. 
**책임감**은 아래 두 종류로 구분해 볼 수 있습니다.
- *퍼포먼스* 를 위한 테스트가 이뤄져야 합니다.
- 모델로부터의 `예측 결과`는 *위변조 방지* 가 되어야 하고, 원래 모델로 *추적이 가능*해야 합니다.

하지만 현재는 상기한 부분에 대해 아래와 같은 장애물이 있습니다.

- ML 모델은 *BlackBox* 방식으로 사용되며, `증명가능`한 속성보다는 `광범위한 테스트`를 통해 품질이 관리됩니다.
- 최신 모델은 크기가 **매우** 큽니다. 따라서, 이러한 컴퓨팅 리소스를 가진 *일부* 회사가 모델의 예측을 `위변조할 위험`이 있습니다.

게다가 대규모 ML 모델은 학습을 위해 방대한 양의 데이터와 컴퓨팅이 필요한 경우가 많으며, 
이러한 학습 과정에서 도출된 *parameter*는 그 자체로 귀중한 지적 재산이 되는 경우가 많습니다. 
결과적으로 `모델 소유자`는 이러한 귀중한 자산을 숨기려는 동기가 생기고, 감사나 공개 검증 기법 등이 제대로 작동하지 못하게 됩니다. 
개인 정보를 보호하는 ML 모델의 책임성에 대한 이러한 요구는 초기 단계이지만 
빠르게 발전하고 있는 *머신러닝에 대한 검증 가능성 기술* 인 `영지식 머신러닝(ZKML)`을 개선하기 위한 노력의 동기가 되었습니다.

## 1.1 ZKML
영지식 머신 러닝(ZKML)은 필요할 때마다 영지식 속성을 포함하는 SNARK를 머신 러닝 알고리즘에 적용하는 것을 말합니다. 
이 논문에서 제시된 것을 포함하여 대부분의 `ZKML 인스턴스`는 추론(*inference*) 에 중점을 두고 있습니다. 
머신 러닝 추론에 적용되는 ZKML은 고정된 아키텍처 $f$와 가중치 $w$를 가진 특정 머신 러닝 모델이 
입력 $x$에 대해 실행될 때 실제로 특정 출력 $\hat{y}$를 산출한다는 **증명**을 생성하는 프로세스를 말합니다. 
결정적으로, 이는 *증명 수신자*가 <u>모델 파라미터 자체를 공개할 필요 없이 
추론 결과를 해당 모델과 입력에 귀속시킬 수 있도록</u> 하여 앞서 언급한 개인정보 보호 책임이라는 요구를 충족함으로써 모델에 **책임성**을 부여할 수 있게 해줍니다. 
또한, `ZKML`은 Scalability 및 Privacy 와 관련하여 매우 유용하게 사용할 수 있는 SNARK의 몇 가지 주요 속성을 제공합니다:
- ZKML 증명은 킬로바이트에서 메가바이트로 그 크기가 간결합니다.
- ZKML 증명은 모델 크기에 따라 검증 시간이 비선형적으로 확장되므로 쉽게 검증할 수 있습니다.
- ZKML 증명은 누구나 언제든 검증할 수 있습니다.
- ZKML 증명은 선택적으로 모델 매개변수의 하위 집합 및/또는 입력 데이터를 검증자로부터 숨길 수 있습니다.

## 1.2 Example Application
정교한 ML 모델을 통해 자산 평가 가격을 계산하는 `trust-minimum 가격 오라클`의 경우를 예로 들어보겠습니다.
이 경우 지식재산권 및 게임화의 이유로 *모델 매개변수* 를 비공개로 유지해야 합니다
(특히 `사용자`가 입력을 수정하여 감정 가격을 어느 방향으로든 최적화할 수 없어야 합니다). 
그러나 이는 잠재적인 공격에 노출될 여지가 큰데, `ML 모델 운영자`(즉, 평가 모델을 실행하고 결과를 보고하는 당사자)가 
알고리즘의 실행을 완전히 제어할 수 있기 때문에 <u>원하는 감정가를 산출하기 위해 원하는 방식으로 알고리즘을 수정(tampering)</u>할 수 있기 때문입니다. 

이러한 위험을 방지하고 <u>모든 자산에 동일한 평가 모델이 균일하게 적용</u>되도록 하기 위해 ZKML을 사용할 수 있습니다. 
먼저, `ML 모델 소유자`는 <u>(1) *공개 모델 아키텍처*</u> 와 <u>(2) *모델 매개변수에 대한 암호화 커미트먼트(암호화 약정)*</u> 를 생성합니다. 
다음으로, 모델에 자산 평가 가격이 질의(query)될 때마다 `ML 모델 운영자`는 앞서 언급한 <u>(1) 아키텍처</u>와 <u>(2) 커미트먼트</u>를 활용해 
네트워크 내의 모든 사람이 검증할 수 있는 <u>(3) *결과*</u> 와 함께 <u>(4) *증명*</u> 을 생성합니다. 
<u>(2) 커미트먼트</u>는 암호학적으로 숨겨져 있기 때문에 **모델 매개변수 자체에 대한 정보는 유출되지 않습니다**. 
또한 암호적으로 **바인딩**되므로, <u>(2) 커미트먼트</u> 를 사용하여 증명이 성공적으로 확인된 모든 출력은 
커미트먼트가 생성된 것과 동일한 매개변수를 사용하는 <u>(1) 아키텍처</u> 로 모델을 실행하여 나온 것이어야 합니다. 
즉, 모든 평가를 생성하는 데 **동일한 모델**을 사용해야 하며, 조작은 불가능하게 됩니다.

블록체인 애플리케이션을 위한 AI 추론으로 확장하면서, 변조 위험성을 의미 있게 줄일 수 있는 `ZKML`의 잠재력에도 불구하고, 현재 구현은 실용적이지 못했습니다.
- SNARK는 많은 양의 암호화 오버헤드를 수반하며, 원래 계산을 단독으로 수행할 때보다 생성하는 데 수만 배 더 오래 걸릴 수 있습니다. 
- SNARK는 종종 증명자에게 엄청난 메모리 부하를 부과하며, 계산을 위해 테라바이트의 RAM이 필요한 경우도 쉽게 발생합니다. 
- 최신 ML 모델은 메가플롭에서 테라플롭에 이르기까지 그 규모가 상당히 크며, 그 자체가 최대 수천억 개의 파라미터로 구성되어 있습니다.

유의미한 ML 추론을 검증하는 작업과 관련된 이러한 비용 요소의 조합으로 인해 일반적인 SNARK 증명 시스템의 사용은 완전히 비실용적입니다. 
그러나 ***Specialization*** 은 유망한 솔루션을 제공합니다. 
본 논문에서는 ML 추론을 검증하기 위해 `GKR 기반` 접근 방식을 사용하여 specialization 하기로 결정했습니다.

구체적인 예로, 업샷 테크놀로지스는 자산 평가 작업에 매우 큰 규모의 의사결정 포레스트 모델(Decision Forest Model)을 적용합니다. 
그들의 첫 번째 온체인(on-chain) 가격 오라클의 경우, 
2500개 이상의 `gradient-boosted decision tree`로 구성된 모델을 사용하여 개별 NFT 자산의 세분화된 가격을 예측합니다. 
섹션 3에서 설명한 `decision forest inference`를 위한 증명 시스템 구현을 통해,
본 논문은 특히 그림 8a, 8b에서 볼 수 있듯이 이전에 알려진 것보다 훨씬 적은 증명자 오버헤드(prover overhead)로 해당 모델이 생성한 평가 가격(appraisal price)을 검증할 수 있습니다.

## 1.3 Our Contribution

*prover-side* 에서 모델과 입력 크기에 따른 *런타임 및 확장성 문제* 를 해결하기 위해, 논문에서는 다음 세 가지 주요 기여를 제시합니다:

1. **GKR [GKR08] 증명 시스템의 고도로 최적화된 버전인 'Remainder'를 구현했습니다.**

    이는 주로 섹션 2.1.2에서 소개되는 구조화된 회로(`structured circuit`)를 염두에 두고 설계되었으며, 
    `Fiat-Shamir 방식`을 통해 비대화(interactive)로 전환되었고, 
    회로의 입력 레이어(input layer)에서 Ligero [AHIV17]의 다항식 *commitment* 로 구현되었습니다. 
    이를 통해 GKR 맥락에서 <u>여러 클레임을 단일 클레임으로 집계하는 휴리스틱 방법이 도입</u>되어, 실제 적용 시 상당한 <u>***성능 개선을 달성***</u> 했습니다.

2. **Libra [XZZ+19]와 Giraffe [WJB+17]의 알고리즘적 발전을 결합했습니다.**
    
    이로써 *data-parallel Addition and Mutiplication* 에 대해 
    $O(2^{b+s_{i+1}})$의 시간 복잡도를 가지는 합체크(sumcheck) 증명자를 구현했습니다(섹션 3.5 참조). 
    여기서 $2^b$는 *data-parallel subcircuit copy* 의 수이며, $2^{2s_{i+1}}$는 `source layer` 의 크기입니다.

3. **ZKDT 논문 [ZFZS2-]의 회로(circuit)를 계층화된 형식(layered format)으로 구현하여 Decision forest 버전을 구현하였습니다.**

    이를 통해 데이터 병렬 환경에서 입력 크기에 맞게 회로를 확장하며 완벽한 이진 트리와 길이 $2^k - 1$의 정렬된 리스트 사이의 
    자연스러운 *일대일 대응을 활용* 해 <u>***해싱 병목을 제거***</u> 했습니다.

## 1.4 Related Works

ZKML (Zero-Knowledge Machine Learning) 문헌들에서 관련 작업을 강조하며, 'Cost of Intelligence' 논문 [Lab23]에서 더 포괄적인 문헌 리뷰를 확인할 수 있습니다. 
아래 표는 기존 연구들을 정리한 자료입니다.

| 연구                  | 주요 특징                                                                                                                                                                                                    | 증명 시스템  |
| ------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------- |
| **ZEN [FQZ+21]**    | - ZKML 시스템의 초기 구현 중 하나  <br>- 효율적인 검증 가능한 곱셈을 위해 stranded encoding 사용                                                                                                                                    | Groth16 |
| **vCNN [LKKO20]**   | - 비선형 레이어에 대해 Quadratic Arithmetic Programs 사용  <br>- 컨볼루션 레이어에 대해 Quadratic Polynomial Programs 사용  <br>- 선형 연산에 효율적인 증명 기술을 활용하고 활성화 함수에 유연한 접근 제공                                                     | 다양한 시스템 |
| **[KHS22]**         | - MobileNetV2 [SHZ+18]의 연산을 인코딩하기 위해 Halo2 증명 시스템의 유연성 사용  <br>- 증명 효율성을 위해 맞춤형 게이트 및 조회 인수 활용                                                                                                           | Halo2   |
| **zkCNN [LXZ21]**   | - GKR(Goldwasser-Kalai-Rothblum) 변형을 사용하여 VGG-16 model [SZ14] 를 증명<br>- [Tha13]의 sumcheck 행렬 곱셈 알고리즘 사용  <br>- CNN 내의 convolution layer의 효율적인 증명을 위해 FFT 연산을 증명하는 새로운 linear-time sumcheck 인수(argument)를 도입 | GKR 변형  |
| **ZKDT ([ZFZS20])** | - `의사 결정 트리`의 정확한 추론을 검증하는 새로운 회로 도입  <br>- Aurora를 백엔드 증명 시스템으로 사용하는 R1CS에 회로 구현                                                                                                                          | Aurora  |
| **[CFF+23]**        | - *matrix lookup arguments* 도입  <br>- decision tree의 모든 가능한 경로를 행렬(matrix)로 인코딩하여, 의사 결정 트리의 정확한 추론 실행을 검증                                                                                                                                        | 다양한 시스템 |

본 논문에서의 결과물은 상기한 `ZEN`, `vCNN`, `[KHS22]`와 달리, `refined version of GKR protocol`을 증명 시스템의 백엔드로 사용한다는 차별점을 가집니다.
또한, `zkCNN`과 달리, `Libra` 논문으로부터의 기술에만 의존하지 않고 `Thaler [Tha13]`, `Giraffe [WJB+17]` 에서의 기술도 활용하여 *병렬적* 이고 *구조적* 인 방식으로 circuit을 구현하였다는 차별점을 갖습니다.
`[CFF+23]`과 달리, decision tree 의 경로(path)를 `layered circuit`으로 인코딩하며 *matrix subset argument* 대신에 `sumcheck`를 이용해 correctness 를 검사합니다.
마지막으로, `ZKDT` 논문에서는 `R1CS`로 회로를 구성한 것과 달리, 모든 decision tree circuit을 *구조적*이고 *층계적(layered)* 이며, *병렬적* 으로 데이터를 다룰 수 있는 circuit으로 구성합니다.
처리해야하는 입력 샘플의 수에 따라 *sublinear data parallel* 이 가능하도록 `input multiset` 을 추가하기도 합니다.
그리고, `ZKDT`에서의 `Aurora` 대신, `Ligero` 논문에서의 *polynomial commitment* 를 이용하는 **GKR** 을 사용한다는 점도 다릅니다.

섹션 4에서 소개되는 벤치마크는 본 논문에서 소개하는 $Remainder$ 의 효율성과 확장성을 보여주며, 이에 대해 아래와 같이 정리할 수 있습니다.
- 3.5장 벤치마크: 알고리즘의 선형적 특성을 강조하며, Giraffe [WJB+17]와 Libra [XZZ+19]의 기법을 결합하여 사용함.
- Prover 기법: 구조화된 방식으로 표현할 수 없는 회로의 부분에만 적용됨.
- 의사결정 포레스트 추론에 대한 실험:
    - 증명 과정과 단순 추론 과정을 비교함.
    - 증명에 소요되는 오버헤드가 상대적으로 낮음.
    - 최소 증명 오버헤드는 (2^7)개의 트리와 (2^7)개의 입력 샘플을 가진 의사결정 포레스트에서 180배이며, 이는 해당 모델을 사용한 입력의 순수 평가와 비교한 수치임.


# 2. Preliminaries
**GKR** 과 **Decision tree** 를 이해하기 위해 필요한 선수 지식에 대해 다룹니다.

## 2.1 GKR
여기서는 아래 다섯가지 개념에 대해 다룹니다.
- Multilinear Extensions (MLE)
- sumcheck protocol
- GKR
- Input data prallel GKR
- GKR for structured circuits

또한, 모든 연산은 유한체 $\mathbb{F}$ 상에서 일어난다고 가정합니다.

### 2.1.1 Multilinear Polynomial
$n$ 개의 변수를 갖는 임의의 다항식 $p(x_1, \dots, x_n)$ 는 모든 $x_i$의 차수(degree)가 **최대 1**일 때, *multilinear* 입니다.
본 논문에서는 추후 *multilinear polynomial* 에 대한 `Lagrange basis`를 다룰 예정입니다.

### 2.1.2 Multilinear Extensions
아래와 같은 임의의 함수 $f$ 에 대하여

$$
\begin{align}
f \quad : \quad \\{0, 1\\}^{n} \rightarrow \mathbb{F}
\end{align}
$$

아래와 같은 함수 $\tilde{f}$ 를 *multilinear extension (MLE)* 라 부릅니다.

$$
\begin{align}
\tilde{f} \quad : \quad \mathbb{F}^n \rightarrow \mathbb{F}
\end{align}
$$

즉, 아래와 같은 *unique* 한 함수 $\tilde{f}(x_1, \dots, x_n)$ 를 정의할 수 있습니다.

$$
\begin{align}
\tilde{f}(z) = \sum_{w \in \\{0, 1\\}^n} f(w) \cdot \tilde{\beta}(w, z)
\end{align}
$$

그리고, $\tilde{\beta}(x, z)$ 는 $w$번째 *Lagrange basis polynomial*로 아래와 같이 정의됩니다.

$$
\begin{align}
\tilde{\beta}(w, z) = \prod^{n}_{i = 1} (w_i \cdot z_i + (1 - w_i) \cdot (1 - z_i))
\end{align}
$$

또한, $\tilde{\beta}(x, z)$는 점 함수(point function)의 MLE 로써 아래와 같이 정의됩니다.

$$
\tilde{\beta}(x,z)=
\begin{cases}
1 \quad \text{if} \quad w = z, \newline
0 \quad \text{otherwise}
\end{cases}
$$
